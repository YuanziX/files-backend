package resolver

// This file will be automatically regenerated based on the schema, any resolver implementations
// will be copied through when generating and any unknown code will be moved to the end.
// Code generated by github.com/99designs/gqlgen version v0.17.80

import (
	"context"
	"fmt"
	"time"

	"github.com/YuanziX/files-backend/internal/database/postgres"
	"github.com/YuanziX/files-backend/internal/graph/generated"
	"github.com/YuanziX/files-backend/internal/graph/model"
	"github.com/YuanziX/files-backend/internal/utils"
	"github.com/aws/aws-sdk-go-v2/service/s3"
	"github.com/google/uuid"
	"github.com/jackc/pgx/v5/pgtype"
)

// ID is the resolver for the id field.
func (r *fileResolver) ID(ctx context.Context, obj *postgres.File) (string, error) {
	panic(fmt.Errorf("not implemented: ID - id"))
}

// Size is the resolver for the size field.
func (r *fileResolver) Size(ctx context.Context, obj *postgres.File) (int32, error) {
	panic(fmt.Errorf("not implemented: Size - size"))
}

// MimeType is the resolver for the mimeType field.
func (r *fileResolver) MimeType(ctx context.Context, obj *postgres.File) (string, error) {
	panic(fmt.Errorf("not implemented: MimeType - mimeType"))
}

// UploadDate is the resolver for the uploadDate field.
func (r *fileResolver) UploadDate(ctx context.Context, obj *postgres.File) (*time.Time, error) {
	panic(fmt.Errorf("not implemented: UploadDate - uploadDate"))
}

// ID is the resolver for the id field.
func (r *folderResolver) ID(ctx context.Context, obj *postgres.Folder) (string, error) {
	panic(fmt.Errorf("not implemented: ID - id"))
}

// CreatedAt is the resolver for the createdAt field.
func (r *folderResolver) CreatedAt(ctx context.Context, obj *postgres.Folder) (*time.Time, error) {
	panic(fmt.Errorf("not implemented: CreatedAt - createdAt"))
}

// PreUploadCheck is the resolver for the preUploadCheck field.
func (r *mutationResolver) PreUploadCheck(ctx context.Context, files []*model.PreUploadFileInput) (*model.PreUploadCheckResponse, error) {
	userIDStr, ok := utils.GetUserID(ctx)
	if !ok {
		return nil, fmt.Errorf("access denied")
	}
	ownerID, err := uuid.Parse(userIDStr)
	if err != nil {
		return nil, fmt.Errorf("invalid user ID in token")
	}

	var completedFiles []*postgres.File
	var newFiles []*model.PreSignedURL

	for _, fileInput := range files {
		// 1. Check if the hash already exists in our database.
		physicalFile, err := r.DB.GetPhysicalFileByHash(ctx, fileInput.Hash)

		if err == nil {
			// 2a. DUPLICATE FOUND: The file content already exists.
			// We just create a new reference to it for the current user.
			params := postgres.CreateFileReferenceParams{
				OwnerID:        pgtype.UUID{Bytes: ownerID, Valid: true},
				PhysicalFileID: physicalFile.ID,
				Filename:       fileInput.Filename,
			}
			newFileRef, err := r.DB.CreateFileReference(ctx, params)
			if err != nil {
				return nil, fmt.Errorf("could not create file reference for %s: %w", fileInput.Filename, err)
			}
			completedFiles = append(completedFiles, &newFileRef)

		} else {
			// 2b. NEW FILE: The content does not exist yet.
			// We generate a pre-signed URL for the client to upload the file to MinIO.
			objectName := fileInput.Hash // Store the file in MinIO using its hash as the key.
			expiry := 15 * time.Minute   // The link will be valid for 15 minutes.

			presignedURL, err := r.S3PresignClient.PresignPutObject(ctx, &s3.PutObjectInput{
				Bucket: &r.S3BucketName,
				Key:    &objectName,
			}, s3.WithPresignExpires(expiry))
			if err != nil {
				return nil, fmt.Errorf("could not generate pre-signed URL for %s: %w", fileInput.Filename, err)
			}

			newFiles = append(newFiles, &model.PreSignedURL{
				Filename:  fileInput.Filename,
				Hash:      fileInput.Hash,
				UploadURL: presignedURL.URL,
			})
		}
	}

	return &model.PreUploadCheckResponse{
		CompletedFiles: completedFiles,
		NewFiles:       newFiles,
	}, nil
}

// ConfirmUploads is the resolver for the confirmUploads field.
func (r *mutationResolver) ConfirmUploads(ctx context.Context, uploads []*model.ConfirmUploadInput) ([]*postgres.File, error) {
	panic(fmt.Errorf("not implemented: ConfirmUploads - confirmUploads"))
}

// CreateFolder is the resolver for the createFolder field.
func (r *mutationResolver) CreateFolder(ctx context.Context, name string, parentID *string) (*postgres.Folder, error) {
	panic(fmt.Errorf("not implemented: CreateFolder - createFolder"))
}

// DeleteFile is the resolver for the deleteFile field.
func (r *mutationResolver) DeleteFile(ctx context.Context, fileID string) (bool, error) {
	panic(fmt.Errorf("not implemented: DeleteFile - deleteFile"))
}

// MyFiles is the resolver for the myFiles field.
func (r *queryResolver) MyFiles(ctx context.Context) ([]*postgres.File, error) {
	panic(fmt.Errorf("not implemented: MyFiles - myFiles"))
}

// File returns generated.FileResolver implementation.
func (r *Resolver) File() generated.FileResolver { return &fileResolver{r} }

// Folder returns generated.FolderResolver implementation.
func (r *Resolver) Folder() generated.FolderResolver { return &folderResolver{r} }

// Mutation returns generated.MutationResolver implementation.
func (r *Resolver) Mutation() generated.MutationResolver { return &mutationResolver{r} }

// Query returns generated.QueryResolver implementation.
func (r *Resolver) Query() generated.QueryResolver { return &queryResolver{r} }

type fileResolver struct{ *Resolver }
type folderResolver struct{ *Resolver }
type mutationResolver struct{ *Resolver }
type queryResolver struct{ *Resolver }
